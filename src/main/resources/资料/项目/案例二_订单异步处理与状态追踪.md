

### 难度：★★★

#### 场景描述
- 用户下单后，订单信息写入Kafka。
- 消费端异步处理订单（如扣库存、发货），订单状态写入HBase。
- Redis缓存最新订单状态，便于用户实时查询。

#### 技术点
- Kafka异步解耦
- HBase宽表设计（orderId为rowkey，status为列）
- Redis缓存热点订单状态


## 1. Producer：模拟下单写入Kafka

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import java.util.Properties;
import java.util.Random;

public class OrderProducer {
    public static void main(String[] args) throws Exception {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        Random random = new Random();
        for (int i = 1; i <= 20; i++) {
            String orderId = "O" + (1000 + i);
            String userId = "user" + (random.nextInt(10) + 1);
            double amount = Math.round((10 + random.nextDouble() * 990) * 100) / 100.0;
            String orderJson = String.format("{\"orderId\":\"%s\",\"userId\":\"%s\",\"amount\":%.2f}", orderId, userId, amount);

            producer.send(new ProducerRecord<>("order", orderId, orderJson));
            System.out.println("下单消息: " + orderJson);
            Thread.sleep(500);
        }
        producer.close();
    }
}
```

---

## 2. Consumer：处理订单，写HBase和Redis

```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;
import redis.clients.jedis.Jedis;
import org.json.JSONObject;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;

import java.io.IOException;
import java.time.Duration;
import java.util.*;

public class OrderConsumer {
    public static void main(String[] args) throws IOException {
        // Kafka Consumer配置
        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "localhost:9092");
        kafkaProps.put("group.id", "order-group");
        kafkaProps.put("key.deserializer", StringDeserializer.class.getName());
        kafkaProps.put("value.deserializer", StringDeserializer.class.getName());
        kafkaProps.put("enable.auto.commit", "true");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(kafkaProps);
        consumer.subscribe(Collections.singletonList("order"));

        // Redis连接
        Jedis jedis = new Jedis("localhost", 6379);

        // HBase连接
        Configuration hbaseConf = HBaseConfiguration.create();
        hbaseConf.set("hbase.zookeeper.quorum", "localhost");
        Connection hbaseConn = ConnectionFactory.createConnection(hbaseConf);
        Table table = hbaseConn.getTable(TableName.valueOf("order"));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
            for (ConsumerRecord<String, String> record : records) {
                JSONObject order = new JSONObject(record.value());
                String orderId = order.getString("orderId");
                String userId = order.getString("userId");
                double amount = order.getDouble("amount");

                // 处理业务逻辑（这里直接模拟为PAID）
                String status = "PAID";
                long ts = System.currentTimeMillis();

                // 写入HBase
                Put put = new Put(orderId.getBytes());
                put.addColumn("info".getBytes(), "userId".getBytes(), userId.getBytes());
                put.addColumn("info".getBytes(), "amount".getBytes(), String.valueOf(amount).getBytes());
                put.addColumn("status".getBytes(), "latest".getBytes(), status.getBytes());
                put.addColumn("status".getBytes(), ("history_" + ts).getBytes(), status.getBytes());
                table.put(put);

                // 写入Redis缓存（5分钟）
                jedis.setex("order:status:" + orderId, 300, status);

                System.out.printf("已处理订单: orderId=%s, userId=%s, amount=%.2f, status=%s%n", orderId, userId, amount, status);
            }
        }
        // jedis.close(); table.close(); hbaseConn.close(); // 实际应加finally关闭
    }
}
```

---

## 3. HBase 表建表命令（提前用hbase shell执行）

```bash
create 'order', 'info', 'status'
```

---

## 4. 练习题代码——查询订单状态

### 查询Redis缓存中的订单状态

```java
import redis.clients.jedis.Jedis;

public class QueryOrderStatusRedis {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        String orderId = "O1001"; // 改成你实际的orderId
        String status = jedis.get("order:status:" + orderId);
        System.out.println("订单" + orderId + "的最新状态：" + status);
        jedis.close();
    }
}
```

### 查询HBase中订单的历史状态

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;

public class QueryOrderStatusHBase {
    public static void main(String[] args) throws Exception {
        Configuration hbaseConf = HBaseConfiguration.create();
        hbaseConf.set("hbase.zookeeper.quorum", "localhost");
        Connection hbaseConn = ConnectionFactory.createConnection(hbaseConf);
        Table table = hbaseConn.getTable(TableName.valueOf("order"));

        String orderId = "O1001"; // 改成你实际的orderId
        Get get = new Get(orderId.getBytes());
        Result result = table.get(get);

        byte[] latest = result.getValue("status".getBytes(), "latest".getBytes());
        System.out.println("订单" + orderId + "的最新状态：" + (latest == null ? "无" : new String(latest)));

        // 查询所有历史状态
        NavigableMap<byte[], byte[]> familyMap = result.getFamilyMap("status".getBytes());
        if (familyMap != null) {
            for (Map.Entry<byte[], byte[]> entry : familyMap.entrySet()) {
                String col = new String(entry.getKey());
                String val = new String(entry.getValue());
                if (col.startsWith("history_")) {
                    System.out.println("历史状态[" + col + "]：" + val);
                }
            }
        }
        table.close();
        hbaseConn.close();
    }
}
```

---

## 5. 依赖（pom.xml）

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>4.0.0</version>
</dependency>
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
    <version>4.4.3</version>
</dependency>
<dependency>
    <groupId>org.apache.hbase</groupId>
    <artifactId>hbase-client</artifactId>
    <version>2.5.8</version>
</dependency>
<dependency>
    <groupId>org.json</groupId>
    <artifactId>json</artifactId>
    <version>20230618</version>
</dependency>
```

---

## 6. 说明

- Producer端批量生成订单伪数据。
- Consumer端异步处理订单、写入HBase和Redis。
- 查询端可实时/历史查询订单状态。
- 可扩展为订单多状态流转、状态变更通知等业务。
